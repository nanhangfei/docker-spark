FROM bde2020/hadoop-base:2.0.0-hadoop3.1.1-java8

MAINTAINER Gezim Sejdiu <g.sejdiu@gmail.com>

ENV ENABLE_INIT_DAEMON true
ENV INIT_DAEMON_BASE_URI http://identifier/init-daemon
ENV INIT_DAEMON_STEP spark_master_init

ENV SPARK_VERSION=2.4.0

COPY wait-for-step.sh /
COPY execute-step.sh /
COPY finish-step.sh /

#COPY bde-spark.css /css/org/apache/spark/ui/static/timeline-view.css

# ADD https://raw.githubusercontent.com/guilhem/apt-get-install/master/apt-get-install /usr/bin/
COPY apt-get-install /usr/bin/
RUN chmod +x /usr/bin/apt-get-install

# RUN wget https://mirrors.huaweicloud.com/apache/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-without-hadoop.tgz \
#       && tar -xvzf spark-${SPARK_VERSION}-bin-without-hadoop.tgz \
#       && mv spark-${SPARK_VERSION}-bin-without-hadoop spark \
#       && rm spark-${SPARK_VERSION}-bin-without-hadoop.tgz \
#       #&& cd /css \
#       #&& jar uf /spark/jars/spark-core_2.11-${SPARK_VERSION}.jar org/apache/spark/ui/static/timeline-view.css \
#       && cd /
COPY spark-2.4.0-bin-without-hadoop.tar.gz spark-2.4.0-bin-without-hadoop.tar.gz
RUN tar -xvf spark-${SPARK_VERSION}-bin-without-hadoop.tar.gz \
      && mv spark-${SPARK_VERSION}-bin-without-hadoop spark \
      && rm spark-${SPARK_VERSION}-bin-without-hadoop.tar.gz \
      #&& cd /css \
      #&& jar uf /spark/jars/spark-core_2.11-${SPARK_VERSION}.jar org/apache/spark/ui/static/timeline-view.css \
      && cd /

ENV SPARK_HOME /spark/

# RUN apt-get-install -y python3 python3-setuptools python3-pip
RUN apt-get-install vim

#Give permission to execute scripts
RUN chmod +x /wait-for-step.sh && chmod +x /execute-step.sh && chmod +x /finish-step.sh

# Fix the value of PYTHONHASHSEED
# Note: this is needed when you use Python 3.3 or greater
ENV PYTHONHASHSEED 1

COPY hive-site.xml /spark/conf/
COPY spark-env.sh /spark/conf/
COPY spark-defaults.conf /spark/conf/

COPY entrypoint.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/entrypoint.sh

ENTRYPOINT ["entrypoint.sh"]
